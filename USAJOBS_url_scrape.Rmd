---
title: "USAJOBS Scrape"
author: "Maxwell Miller-Golub"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
options(max.print=1000000)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
```

```{r urls}
# Each page for the urls below contain 25 hits for public sector jobs.

#keywords: Data Analyst
url1 = "https://www.usajobs.gov/Search/Results?jt=Data%20Analyst"
#keywords: Data Engineer
url2 = "https://www.usajobs.gov/Search/Results?jt=Data%20Engineer"
#keywords: Data Scientist
url3 = "https://www.usajobs.gov/Search/Results?jt=Data%20Scientist"

```


```{r selenium}
library(tidyverse)
library(RSelenium)
library(rvest)
library(netstat)
library(data.table)
library(wdman)
rs_driver_object <- rsDriver(browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
                             chromever = NULL,
                             geckover = "latest",
                             iedrver = NULL,
                             phantomver = "2.1.1",
                             verbose = FALSE,
                             check = TRUE,
                             port = free_port())

remDr <- rs_driver_object$client

remDr$open()
remDr$navigate(url2)

data_scientist_url_list <- list()
data_analyst_url_list <- list()
data_engineer_url_list <- list()

cond <- TRUE

while (cond == TRUE) {
Sys.sleep(0.5)
  
job_list_rough <- remDr$getPageSource()[[1]] %>%
  read_html() %>% html_nodes('a') %>% html_attr('href') 

page_urls <- list()

for (i in job_list_rough){
  if (grepl("/job/", i) == TRUE){
    page_urls <- append(page_urls, i)
  }
}
data_engineer_url_list <- rbindlist(list(data_engineer_url_list, page_urls))

tryCatch(
  {
    next_button <- remDr$findElement(using = "xpath", '//a[@class="usajobs-search-pagination__next-page"]')
    next_button$clickElement()
  },
  error=function(e) {
    print("Script Complete!")
    cond <<- FALSE
  }
)
if (cond == FALSE){
  break
}
}

data_engineer_url_list
```

```{r output_csv}
# The following couple lines of code can't just be repeated. The extra page urls from running the code chunk above will be added back to the data before exporting it to txt files below.

#extra_data_scientist_urls <- page_urls
#extra_data_analyst_urls <- page_urls
#extra_data_engineer_urls <- page_urls


# Time to export. After establishing the "leading url" to add to the beginning of each href, the code will append the last couple of urls that didn't fit (because rbindlist was looking for exactly 25 inputs and the last page didnt have 25). After appending the final urls, capture.output creates an output file of all urls. The result is 3 text files with (likely some overlapping) urls that each lead to a single job posting. The next step will take each url and scrape it for pertinent information

leading_url <- "https://www.usajobs.gov"



appendable_analyst_url_list <- c()
for (section in data_analyst_url_list){
  for (row in section) {
    for (i in row) {
      i <- paste(leading_url, i, sep = "")
      appendable_analyst_url_list <- append(appendable_analyst_url_list, i)
    }
  }
}


for (row in extra_data_analyst_urls){
  for (i in row) {
    i <- paste(leading_url, i, sep = "")
    appendable_analyst_url_list <- append(appendable_analyst_url_list, i)
  }
}

appendable_analyst_url_list


capture.output(appendable_analyst_url_list, file = "data_analyst_urls.txt")

######################################################################

# Do the same for data scientist list

appendable_scientist_url_list <- c()
for (section in data_scientist_url_list){
  for (row in section) {
    for (i in row) {
      i <- paste(leading_url, i, sep = "")
      appendable_scientist_url_list <- append(appendable_scientist_url_list, i)
    }
  }
}


for (row in extra_data_scientist_urls){
  for (i in row) {
    i <- paste(leading_url, i, sep = "")
    appendable_scientist_url_list <- append(appendable_scientist_url_list, i)
  }
}

capture.output(appendable_scientist_url_list, file = "data_scientist_urls.txt")


######################################################################
# Do the same for data engineer list

appendable_engineer_url_list <- c()
for (section in data_engineer_url_list){
  for (row in section) {
    for (i in row) {
      i <- paste(leading_url, i, sep = "")
      appendable_engineer_url_list <- append(appendable_engineer_url_list, i)
    }
  }
}


for (row in extra_data_engineer_urls){
  for (i in row) {
    i <- paste(leading_url, i, sep = "")
    appendable_engineer_url_list <- append(appendable_engineer_url_list, i)
  }
}


capture.output(appendable_engineer_url_list, file = "data_engineer_urls.txt")

```


```{r indie_url_test}
sample_url <- "https://www.usajobs.gov/job/818787600"

library(tidyverse)
library(RSelenium)
library(rvest)
library(netstat)
library(data.table)
library(wdman)
rs_driver_object <- rsDriver(browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
                             chromever = NULL,
                             geckover = "latest",
                             iedrver = NULL,
                             phantomver = "2.1.1",
                             verbose = FALSE,
                             check = TRUE,
                             port = free_port())


remDr <- rs_driver_object$client

remDr$open()
remDr$navigate(sample_url)

html <- remDr$getPageSource()[[1]] %>%
  read_html() 

remote_data <- html %>% html_elements(".usajobs-joa-summary__grades") %>% html_text2()

#"Pay scale & grade": remote_data[[1]]
#"Remote job": remote_data[[2]]
#"Telework eligible": remote_data[[3]]
#"Travel Required": remote_data[[4]]
#"Relocation expenses reimbursed": remote_data[[5]]


extra_details <- html %>% html_elements(".usajobs-joa-summary__value") %>% html_text2()

#"Appointment type": extra_details[[2]]
#"Work schedule": extra_details[[3]]
#"Hiring Process": extra_details[[4]]
#"Promotion Potential": extra_details[[5]]
#"Supervisory Status": extra_details[[6]]
#"Security Clearance": extra_details[[7]]
#"Drug Test": extra_details[[8]]


salary <- strsplit("$74,441 - $135,987 per year", " ")
#salary_max <- strsplit("$74,441 - $135,987 per year", " ")[[3]]
salary_min <- salary[[1]][1]
salary_max <- salary[[1]][3]
salary_min
salary_max

#Glossary:
# pay scale and grade: A grade refers to the pay scale which sets the pay level and qualifications for the job.

# Telework elligible: Determines if you will be able to work from home on some days.
# travel required: The amount of travel the job requires.

# relocation expenses reimbursed: Whether or not you will be reimbursed for relocation expenses.

# appointment type: The way that the Federal Government classifies the duration of certain jobs.

# work schedule: Determines the number of hours that you will work during the week.

#hiring process: The Federal Government has three services that determine how you are hired: Competitive, Excepted, and Senior Executive. 

#"Promotion Potential": Determines if you can move up to the next grade within your pay scale.

# supervisory status: Determines if you will be a supervisor.

# security clearance: The level of security clearance required to hold this position.

# Drug Test: Whether or not you will be tested for illegal drug use.



#remDr$getPageSource()[[1]] %>%
#  read_html() %>% html_nodes('a') %>% html_attr('href')

#usajobs-joa-summary__grades

test_url_list <- c( "https://www.usajobs.gov/job/759326100", "https://www.usajobs.gov/job/822710600", "https://www.usajobs.gov/job/821275100", "https://www.usajobs.gov/job/812166900", "https://www.usajobs.gov/job/811561600", "https://www.usajobs.gov/job/821546700", "https://www.usajobs.gov/job/821332600", "https://www.usajobs.gov/job/810753900", "https://www.usajobs.gov/job/820782700", "https://www.usajobs.gov/job/822293400")
```









```{r get_search_length_test}
html = read_html(url1)

html %>% html_element(".usajobs-search-controls__results-count") %>% html_text2()
#html %>% html_element(".usajobs-search-noresults-suggestions") %>% html_text2()
html %>% html_elements("div.page-info")
#html %>% html_elements(".usajobs-search .usajobs-search-noresults-suggestions")

#".usajobs-search-controls__results-count"

#html %>% 
#  html_nodes("*") %>% 
#  html_attr("class") %>% 
#  unique()

#class="usajobs-search-noresults-suggestions"
#.usajobs-search-controls__results-count-container no-params usajobs-search-noresults
```

```{r get_hrefs}

html = read_html(url1)

html %>% 
  html_elements("a") %>% 
  html_attr("href")

html %>% 
  html_elements("h2")


html %>% 
  html_elements(".usajobs-search-result--core__agency")


salary <- strsplit("$74,441 - $135,987 per year", " ")
#salary_max <- strsplit("$74,441 - $135,987 per year", " ")[[3]]
salary_min <- salary[[1]][1]
salary_max <- salary[[1]][3]
salary_min
salary_max
```



```{r extra2}
rs_driver_object <- rsDriver(browser = c("chrome", "firefox", "phantomjs", "internet explorer"),
                             chromever = NULL,
                             geckover = "latest",
                             iedrver = NULL,
                             phantomver = "2.1.1",
                             verbose = TRUE,
                             check = TRUE,
                             port = free_port())
rs_driver_object <- rsDriver(browser = "chrome",
                             chromever = "114.0.5735.90",
                             verbose = FALSE,
                             port = free_port())
element <- remDr$findElement(using = "xpath", '//div[contains(@class, "usajobs-search-result--core"')
element <- remDr$findElements(using = "xpath", '//div[@class="usajobs-search-result--core"')

elements
element <- remDr$findElement(using = "xpath", '//div[contains(@class, "usajobs-search-result--core"')
elements <- remDr$findElements(using = "xpath", '//div[@class="usajobs-search-result--core"')


qualifications
second_try <- remDr$findElement(using = 'class name', 'usajobs-search-result--core__title search-joa-link')
second_try
third_try <- remDr$findElement(using = "xpath", '//a[@class="usajobs-search-save-cta"]')
third_try

#test_list <- c()
#for (i in 1:5){
#  test_list <- append(test_list, i)
#}
#test_list
```








