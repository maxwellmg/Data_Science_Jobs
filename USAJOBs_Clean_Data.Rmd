---
title: "USAJOBs Data Clean"
author: "Maxwell Miller-Golub"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(jsonlite)
```

## R Markdown

```{r clean up dups}
df2 <- rbind(Data_Analyst_Data_Set, Data_Engineer_Data_Set)
full_data_with_dups <- rbind(df2, Data_Scientist_Data_Set)

# Remove duplicates, keeping information from the unique column
df_cleaned <- full_data_with_dups %>%
  group_by(`Job Code`, `Date Accessed`, `Full URL`, Title, Agency, `Pay scale & grade`, `Remote job`, `Telework eligible`, `Travel Required`, `Relocation expenses reimbursed`, `Appointment type`, `Work schedule`, `Hiring Process`, `Promotion Potential`, `Supervisory Status`, `Security Clearance`, `Drug Test`, `salary_min`, `salary_max`, Qualifications) %>%  # Group by all columns except the unique one
  summarize(
    Keyword = paste(unique(Keyword), collapse = ", "),  # Combine the unique_column values
    .groups = "drop"  # Remove grouping structure
  )
```


```{r export tibbles}

write_csv(df_cleaned, "Full_Clean_Data_Jobs_Dataset.csv")
```


```{r fixing_qualification}

# Edit the list of words to remove from Qualifications
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine", "ten")
removal_words <- stopwords::stopwords("en")
removal_words <- append(removal_words, "qualification")
removal_words <- append(removal_words, "qualifications")
removal_words <- append(removal_words, "")
removal_words <- append(removal_words, letters)
removal_words <- append(removal_words, numbers)
removal_words

# The function to clean qualifications paragraphs to be lists of viable words

shrink_qualifications <- function(sample_qualification){
  sample_qualification <- str_replace_all(sample_qualification, "\n", " ")
  sample_qualification <- strsplit(sample_qualification, " ")
  sample_qualification <- lapply(sample_qualification, function(s) s[nchar(s) <= 25])
  sample_qualification <- lapply(sample_qualification, function(s) gsub("[^[:alnum:]]", "", s))
  sample_qualification <- lapply(sample_qualification, tolower)
  sample_qualification <- sample_qualification[[1]]
  sample_qualification <- base::setdiff(sample_qualification, removal_words)
  #sample_qualification <- vapply(sample_qualification, function(x) if (!grepl("^\\d+$", x)) x else NULL, FUN.VALUE = character(1))
  #sample_qualification <- sample_qualification[!is.null(sample_qualification)]
  sample_qualification <- lapply(sample_qualification, function(x) if (!grepl("\\d", x)) x else NULL)
sample_qualification <- base::Filter(base::Negate(is.null), sample_qualification)
sample_qualification <- unlist(sample_qualification)
sample_qualification <- list(sample_qualification)
sample_qualification <- sapply(sample_qualification, function(x) paste(x, collapse = " "))
sample_qualification <- as.character(sample_qualification)
return(sample_qualification)
}

Full_Clean_Data_Jobs_Dataset <- read_csv("~/Desktop/AU_Grad_Cert/Fall_2024/Data_Science/Final Project/Data_Science_Jobs/Full_Clean_Data_Jobs_Dataset.csv")
#typeof(Full_Clean_Data_Jobs_Dataset)

modding_table <- as_tibble(Full_Clean_Data_Jobs_Dataset)

all_3 <- modding_table %>% 
  filter(Keyword == "Data Analyst, Data Engineer, Data Scientist") %>% 
  mutate(Reduced_Qualifications = map(Qualifications, shrink_qualifications))

all_data_for_json <- modding_table %>% 
  mutate(Reduced_Qualifications = map(Qualifications, shrink_qualifications)) %>% 
  select(-Qualifications)

view(all_data_for_json)

clear_qualifications <- modding_table %>% 
  select(-Qualifications)



```


```{r write_to_csv_json}
write_json(all_3, "Only_Definite_Data_Science_Jobs_Dataset.json")
write_json(all_data_for_json, "All_Data_Fixed_Qualifications.json")
write_csv(all_3, "Only_Definite_Data_Science_Jobs_Dataset.csv")
write_csv(clear_qualifications, "Data_Jobs_Dataset_Without_Qualifications.csv")

```

```{r clean columns}
Full_Clean_Data_Jobs_Dataset <- read_csv("~/Desktop/AU_Grad_Cert/Fall_2024/Data_Science/Final Project/Data_Science_Jobs/Full_Clean_Data_Jobs_Dataset.csv")

cleaned_four <- Full_Clean_Data_Jobs_Dataset %>%
  mutate(`Telework eligible` = case_when(
    str_sub(`Telework eligible`, 1, 3) == "Yes" ~ "Yes",
    `Telework eligible` == "No" ~ "No",
    `Telework eligible` == "Not applicable, this is a remote position." ~ "N/A (Remote Position)",
    TRUE ~ "Unspecified"
  )) %>% 
  # Removes 80 cases of the 2500 where the data scraped incorrectly
  filter(`Telework eligible` != "Unspecified") %>% 
  mutate(`Travel Required` = case_when(
    str_starts(`Travel Required`, "25% or less") | 
      str_starts(`Travel Required`, "Occasional travel") ~ "<= 25%",
    str_sub(`Travel Required`, 1, 11) == "50% or less" ~ "<= 50%",
    str_sub(`Travel Required`, 1, 11) == "75% or less" |
      str_sub(`Travel Required`, 1, 14) == "76% or greater" ~ "> 50%",
    `Travel Required` == "Not required" ~ "Not Required",
    TRUE ~ "Unspecified")) %>% 
  filter(`Travel Required` != "Unspecified") %>% 
   mutate(`Work schedule` = case_when(
    str_starts(`Work schedule`, "Full-Time") |
      str_starts(`Work schedule`, "Full-time") ~ "Full-time",
    str_starts(`Work schedule`, "Multiple Schedules") ~ "Multiple Schedules (Schedules may vary depending on agency, position, season, etc.)",
    str_starts(`Work schedule`, "Part-time") ~ "Part-time",
    `Work schedule` == "Intermittent" ~ "Intermittent",
    TRUE ~ "Unspecified")) %>% 
  mutate(`Remote job` = case_when(
    str_sub(`Remote job`, 1, 3) == "Yes" ~ "Yes",
    `Remote job` == "No" ~ "No",
    TRUE ~ "Unspecified"
  ))
  

# Remote Job
cleaned_four %>% 
  group_by(`Remote job`) %>% 
  count(`Remote job`)
```



