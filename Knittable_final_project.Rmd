---
title: "Final_Project_USAJOBs_ETL"
author: "Maxwell Miller-Golub"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)

library(tidyverse)
library(RSelenium)
library(rvest)
library(netstat)
library(data.table)
library(wdman)
library(stopwords)
library(readr)
library(jsonlite)
```

# Step 2: Clean

### 2a) Combine data tables and remove duplicate jobs
```{r clean up dups}
Data_Scientist_Data_Set <- read_csv("Data_Scientist_Data_Set.csv")

Data_Analyst_Data_Set <- read_csv("Data_Analyst_Data_Set.csv")

Data_Engineer_Data_Set <- read_csv("Data_Engineer_Data_Set.csv")

df2 <- rbind(Data_Analyst_Data_Set, Data_Engineer_Data_Set)
full_data_with_dups <- rbind(df2, Data_Scientist_Data_Set)

# Remove duplicates, keeping information from the unique column
df_cleaned <- full_data_with_dups %>%
  group_by(`Job Code`, `Date Accessed`, `Full URL`, Title, Agency, `Pay scale & grade`, `Remote job`, `Telework eligible`, `Travel Required`, `Relocation expenses reimbursed`, `Appointment type`, `Work schedule`, `Hiring Process`, `Promotion Potential`, `Supervisory Status`, `Security Clearance`, `Drug Test`, `salary_min`, `salary_max`, Qualifications) %>%  # Group by all columns except the unique one
  summarize(
    Keyword = paste(unique(Keyword), collapse = ", "),  # Combine the unique_column values
    .groups = "drop"  # Remove grouping structure
  )

#write_csv(df_cleaned, "Full_Clean_Data_Jobs_Dataset.csv")
```

### 2b) Build stopwords out to clean "Qualifications" more
```{r expand stopwords}

# Edit the list of words to remove from Qualifications
numbers <- c("one", "two", "three", "four", "five", "six", "seven", "eight", 
             "nine", "ten")
removal_words <- stopwords::stopwords("en")
removal_words <- append(removal_words, "qualification")
removal_words <- append(removal_words, "qualifications")
removal_words <- append(removal_words, "")
removal_words <- append(removal_words, letters)
removal_words <- append(removal_words, numbers)

```

### 2c) Telework, Travel, Schedule, Remote, Relocation Columns Cleaned and Combined
```{r clean columns}
Full_Clean_Data_Jobs_Dataset <- read_csv("Full_Clean_Data_Jobs_Dataset.csv")

cleaned_five_columns <- Full_Clean_Data_Jobs_Dataset %>%
  mutate(`Telework eligible` = case_when(
    str_sub(`Telework eligible`, 1, 3) == "Yes" ~ "Yes",
    `Telework eligible` == "No" ~ "No",
    `Telework eligible` == "Not applicable, this is a remote position." ~ "N/A (Remote Position)",
    TRUE ~ "Unspecified"
  )) %>% 
  # Removes 80 cases of the 2100 where the data scraped incorrectly
  filter(`Telework eligible` != "Unspecified") %>% 
  mutate(`Travel Required` = case_when(
    str_starts(`Travel Required`, "25% or less") | 
      str_starts(`Travel Required`, "Occasional travel") ~ "<= 25%",
    str_sub(`Travel Required`, 1, 11) == "50% or less" ~ "<= 50%",
    str_sub(`Travel Required`, 1, 11) == "75% or less" |
      str_sub(`Travel Required`, 1, 14) == "76% or greater" ~ "> 50%",
    `Travel Required` == "Not required" ~ "Not Required",
    TRUE ~ "Unspecified")) %>% 
  filter(`Travel Required` != "Unspecified") %>% 
   mutate(`Work schedule` = case_when(
    str_starts(`Work schedule`, "Full-Time") |
      str_starts(`Work schedule`, "Full-time") ~ "Full-time",
    str_starts(`Work schedule`, "Multiple Schedules") ~ "Multiple Schedules (Schedules may vary depending on agency, position, season, etc.)",
    str_starts(`Work schedule`, "Part-time") ~ "Part-time",
    `Work schedule` == "Intermittent" ~ "Intermittent",
    TRUE ~ "Unspecified")) %>% 
  mutate(`Remote job` = case_when(
    str_sub(`Remote job`, 1, 3) == "Yes" ~ "Yes",
    `Remote job` == "No" ~ "No",
    TRUE ~ "Unspecified"
  )) %>% 
  mutate(`Relocation expenses reimbursed` = case_when(
    str_sub(`Relocation expenses reimbursed`, 1, 3) == "Yes" ~ "Yes",
    `Relocation expenses reimbursed` == "No" ~ "No",
    TRUE ~ "Unspecified"
  ))
```

### 2d) Jobs with hourly wages are converted to salaries (based on 40hrs/52wks) 
```{r fix_hourly}
cleaned_seven_columns <- cleaned_five_columns %>% 
  mutate(salary_min = case_when(
    salary_min < 54 & salary_min > 2 ~ salary_min*40*52,
    TRUE ~ salary_min
    )) %>% 
  mutate(salary_max = case_when(
    salary_max < 54 ~ salary_max*40*52,
    TRUE ~ salary_max
    ))

head(cleaned_seven_columns)
```

### 2e) Function to clean qualifications -> create lists of words
```{r qualifications_function}

shrink_qualifications <- function(sample_qualification){
  sample_qualification <- str_replace_all(sample_qualification, "\n", " ")
  sample_qualification <- strsplit(sample_qualification, " ")
  sample_qualification <- lapply(sample_qualification, function(s) s[nchar(s) <= 25])
  sample_qualification <- lapply(sample_qualification, function(s) gsub("[^[:alnum:]]", "", s))
  sample_qualification <- lapply(sample_qualification, tolower)
  sample_qualification <- sample_qualification[[1]]
  sample_qualification <- base::setdiff(sample_qualification, removal_words)
  sample_qualification <- lapply(sample_qualification, function(x) if (!grepl("\\d", x)) x else NULL)
sample_qualification <- base::Filter(base::Negate(is.null), sample_qualification)
sample_qualification <- unlist(sample_qualification)
sample_qualification <- list(sample_qualification)
sample_qualification <- sapply(sample_qualification, function(x) paste(x, collapse = " "))
sample_qualification <- as.character(sample_qualification)
return(sample_qualification)
}
```

### 2f) Clean Qualifications and Export to CSV and JSON
```{r clean_qualifications_and export}

jobs_tibble <- as_tibble(cleaned_seven_columns)

# Splitting data here into different outputs. Cleaning qualifications for the 80 jobs that match on all three keywords (all_3), cleaning qualifications for all jobs for a master table (all_data_for_json), and getting rid of qualifications on the rest to make ShinyApp run more easily (clear_qualifications)

all_3 <- jobs_tibble %>% 
  filter(Keyword == "Data Analyst, Data Engineer, Data Scientist") %>% 
  mutate(Reduced_Qualifications = map(Qualifications, shrink_qualifications))

head(all_3)

all_data_for_json <- jobs_tibble %>% 
  mutate(Reduced_Qualifications = map(Qualifications, shrink_qualifications))

head(all_data_for_json)

clear_qualifications <- jobs_tibble %>% 
  select(-Qualifications)

head(clear_qualifications)

#write_json(all_3, "Only_Definite_Data_Science_Jobs_Dataset.json")
#write_json(all_data_for_json, "All_Data_Fixed_Qualifications.json")
#write_csv(all_3, "Only_Definite_Data_Science_Jobs_Dataset.csv")
#write_csv(clear_qualifications, "Data_Jobs_Dataset_Without_Qualifications.csv")

```

# Step 3: Analysis

### 3a) Logistic Regression of Supervisors and Salary
```{r logistic_regression}

supervisor_data <- cleaned_seven_columns %>% 
  select(`Supervisory Status`, salary_min, salary_max) %>% 
  mutate(supervisor_binary = case_when(
    `Supervisory Status` == "No" ~ 0,
    `Supervisory Status` == "Yes" ~ 1
  ))

glm(supervisor_binary ~ salary_min + salary_max, family = "binomial", data = supervisor_data) -> supervisor_model
summary(supervisor_model)
#plot(supervisor_model)
ggplot(supervisor_data, aes(x=salary_max, y=supervisor_binary)) + 
        geom_point(alpha=.5) +
        stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
ggplot(supervisor_data, aes(x=salary_min, y=supervisor_binary)) + 
        geom_point(alpha=.5) +
        stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial))
```

# 4: Extra

### 4a) Glossary of Terms from USAJOBs
``` {r glossary}
#Glossary:
# pay scale and grade: A grade refers to the pay scale which sets the pay level and qualifications for the job.

# Telework elligible: Determines if you will be able to work from home on some days.
# travel required: The amount of travel the job requires.

# relocation expenses reimbursed: Whether or not you will be reimbursed for relocation expenses.

# appointment type: The way that the Federal Government classifies the duration of certain jobs.

# work schedule: Determines the number of hours that you will work during the week.

#hiring process: The Federal Government has three services that determine how you are hired: Competitive, Excepted, and Senior Executive. 

#"Promotion Potential": Determines if you can move up to the next grade within your pay scale.

# supervisory status: Determines if you will be a supervisor.

# security clearance: The level of security clearance required to hold this position.

# Drug Test: Whether or not you will be tested for illegal drug use.


```

